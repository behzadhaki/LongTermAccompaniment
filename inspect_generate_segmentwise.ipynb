{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T07:36:44.018130Z",
     "start_time": "2024-07-24T07:36:42.294233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from model.LongTermAccompanimentBeatwiseUpcomingBars import LongTermAccompanimentBeatwiseUpcomingBars\n",
    "from model import load_model\n",
    "import torch\n",
    "from hvo_sequence.hvo_seq import HVO_Sequence\n",
    "from hvo_sequence.drum_mappings import ROLAND_REDUCED_MAPPING\n",
    "from bokeh.plotting import show, output_notebook\n",
    "import os\n",
    "import timeit\n",
    "from hvo_sequence.hvo_seq import HVO_Sequence\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "# mdl_ = 'misc/LTA/(Smaller) Predict 1 bar ahead, no velocity at inputs_w2ujjpkp/100.pth'\n",
    "# mdl_ = 'misc/LTA/(Smaller) Predict 2 bar ahead, no velocity at inputs_ycwpquxg/100.pth'\n",
    "\n",
    "mdl_ = 'misc/LTA/(Smaller) Predict 1 bar ahead, no velocity at inputs_5yxlci4h/100.pth'\n",
    "\n",
    "model = load_model(\n",
    "    model_path=mdl_,\n",
    "    model_class=LongTermAccompanimentBeatwiseUpcomingBars,\n",
    "    device='cpu',\n",
    "    is_evaluating=True\n",
    ")\n",
    "\n",
    "model.serialize(save_folder=os.path.dirname(mdl_), filename=mdl_.split('/')[-1].replace('.pth', '.pt'))\n",
    "model.eval()"
   ],
   "id": "f2bed407631586b1",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_look_back_segments: 4\n",
      "n_segments_per_bar:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtic/miniconda3/envs/GrooveTransformer/lib/python3.9/site-packages/torch/jit/_recursive.py:313: UserWarning: 'norm' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LongTermAccompanimentBeatwiseUpcomingBars(\n",
       "  (SegmentEncoder): SegmentEncoder(\n",
       "    (FCN): Linear(in_features=12, out_features=128, bias=True)\n",
       "  )\n",
       "  (PerformanceEncoder): PerformanceEncoder(\n",
       "    (PositionalEncoding): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (Encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (DrumDecoder): DrumDecoder(\n",
       "    (InputLayerEncoder): InputGrooveRhythmLayer(\n",
       "      (velocity_dropout): Dropout(p=0.3, inplace=False)\n",
       "      (offset_dropout): Dropout(p=0.3, inplace=False)\n",
       "      (HitsLinear): Linear(in_features=9, out_features=128, bias=True)\n",
       "      (VelocitiesLinear): Linear(in_features=9, out_features=128, bias=True)\n",
       "      (OffsetsLinear): Linear(in_features=9, out_features=128, bias=True)\n",
       "      (HitsReLU): ReLU()\n",
       "      (VelocitiesReLU): ReLU()\n",
       "      (OffsetsReLU): ReLU()\n",
       "      (PositionalEncoding): PositionalEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (Decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (HitOutputLayer): SingleFeatureOutputLayer(\n",
       "      (Linear): Linear(in_features=128, out_features=9, bias=True)\n",
       "    )\n",
       "    (VelocityOutputLayer): SingleFeatureOutputLayer(\n",
       "      (Linear): Linear(in_features=128, out_features=9, bias=True)\n",
       "    )\n",
       "    (OffsetOutputLayer): SingleFeatureOutputLayer(\n",
       "      (Linear): Linear(in_features=128, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# generate a random pattern\n",
    "hvo = model.generate_random_pattern(n_bars=4)\n",
    "print(hvo.shape)\n",
    "# synthesize and display the pattern\n",
    "hvo_seq = HVO_Sequence(\n",
    "    beat_division_factors=[4],\n",
    "    drum_mapping=ROLAND_REDUCED_MAPPING\n",
    ")\n",
    "hvo_seq.add_tempo(0, 120)\n",
    "hvo_seq.add_time_signature(0, 4, 4)\n",
    "hvo_seq.hvo = hvo[0, :, :].detach().numpy()\n",
    "\n",
    "\n",
    "# load audio player\n",
    "from IPython.display import Audio, display\n",
    "display(Audio(hvo_seq.synthesize(sf_path='hvo_sequence/soundfonts/Standard_Drum_Kit.sf2'), rate=44100))\n",
    "\n",
    "hvo_seq.to_html_plot(show_figure=True, width=800, height=400)\n",
    "\n",
    "model.decoder_input_has_velocity\n",
    "\n"
   ],
   "id": "909a506853a65aba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "start = timeit.default_timer()\n",
    "model.prime_with_drums(hvo)\n",
    "print('Time: ', (timeit.default_timer() - start) * 1000, 'ms')"
   ],
   "id": "bb56b415b87822da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.generations[:, :16, 3], model.shifted_tgt[:, :17, 3], hvo[0, :16, 3]",
   "id": "9ff7c63bccb468fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start = timeit.default_timer()\n",
    "model.encode_input_performance(torch.rand(1, 64, 3))\n",
    "print('Time: ', (timeit.default_timer() - start) * 1000, 'ms')"
   ],
   "id": "4d77aa4471b542b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "eb278b2e86d61ec4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load data\n",
    "\n",
    "from data import PairedLTADatasetV2\n",
    "max_n_bars = 32\n",
    "\n",
    "test_dataset = PairedLTADatasetV2(\n",
    "        input_inst_dataset_bz2_filepath=\"data/lmd/data_bass_groove_test.bz2\",\n",
    "        output_inst_dataset_bz2_filepath=\"data/lmd/data_drums_full_unsplit.bz2\",\n",
    "        shift_tgt_by_n_steps=1,\n",
    "        max_input_bars=max_n_bars,\n",
    "        hop_n_bars=8\n",
    "    )"
   ],
   "id": "ead7e3480bd12ecd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_dataset_longer = PairedLTADatasetV2(\n",
    "        input_inst_dataset_bz2_filepath=\"data/lmd/data_bass_groove_test.bz2\",\n",
    "        output_inst_dataset_bz2_filepath=\"data/lmd/data_drums_full_unsplit.bz2\",\n",
    "        shift_tgt_by_n_steps=1,\n",
    "        max_input_bars=128,\n",
    "        hop_n_bars=32\n",
    "    )"
   ],
   "id": "de0bc62350c0ec1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "be2d0213ddf17365",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "925b0db471416678",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from model.LongTermAccompanimentBeatwiseUpcomingBars import LongTermAccompanimentBeatwiseUpcomingBars\n",
    "from model import load_model\n",
    "import torch\n",
    "from hvo_sequence.hvo_seq import HVO_Sequence\n",
    "from hvo_sequence.drum_mappings import ROLAND_REDUCED_MAPPING\n",
    "from bokeh.plotting import show, output_notebook\n",
    "import os\n",
    "import timeit\n",
    "from hvo_sequence.hvo_seq import HVO_Sequence\n",
    "\n",
    "len_segs = 60\n",
    "model.reset_all()\n",
    "sample_ix = torch.randint(0, len(test_dataset_longer), (1,)).item()\n",
    "input_ = test_dataset_longer.instrument1_hvos[sample_ix].unsqueeze(0)[:, :len_segs*4, :]\n",
    "# model.prime_with_drums(test_dataset_longer.instrument2_hvos[sample_ix].unsqueeze(0)[:, :32, :])\n",
    "gens = torch.zeros((1, input_.shape[1]+32, 27))\n",
    "print(gens.shape)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "for i in range(0, len_segs):#input_.shape[1] // 4 ):\n",
    "    if (i % 4) == 0:\n",
    "        print(f\"-------------------Bar {i // 4}-------------------\")\n",
    "    next_K_bars = model.predict_next_K_bars_starting_at(start_=i * 4, threshold=0.05, print_info=True)\n",
    "    gens[:, i*4:(i*4+next_K_bars.shape[1]), :] = next_K_bars\n",
    "    model.encode_input_performance(input_[:, i*4:(i+1)*4, :])\n",
    "        \n",
    "print('Time: ', (timeit.default_timer() - start) * 1000, 'ms')\n",
    "\n",
    "\n",
    "# play and display the generated pattern\n",
    "hvo_seq_bass = HVO_Sequence(\n",
    "    beat_division_factors=[4],\n",
    "    drum_mapping={'BASS Rhythm': [80]}\n",
    ")\n",
    "hvo_seq_bass.add_tempo(0, 120)\n",
    "hvo_seq_bass.add_time_signature(0, 4, 4)\n",
    "hvo_seq_bass.hvo = input_[0, :, :].detach().numpy()\n",
    "\n",
    "hvo_seq = HVO_Sequence(\n",
    "    beat_division_factors=[4],\n",
    "    drum_mapping=ROLAND_REDUCED_MAPPING\n",
    "    \n",
    "    \n",
    ")\n",
    "hvo_seq.add_tempo(0, 120)\n",
    "hvo_seq.add_time_signature(0, 4, 4)\n",
    "print(input_.shape[1], 48 * 4)\n",
    "hvo_seq.hvo = gens[0, :input_.shape[1], :].detach().numpy()\n",
    "\n",
    "audio1 = hvo_seq.synthesize(sf_path='hvo_sequence/soundfonts/Standard_Drum_Kit.sf2')\n",
    "audio2 = hvo_seq_bass.synthesize(sf_path='hvo_sequence/soundfonts/Standard_Drum_Kit.sf2',track_n=9, program=0)\n",
    "audio1 = audio1[:min(audio1.shape[0], audio2.shape[0])]\n",
    "audio2 = audio2[:min(audio1.shape[0], audio2.shape[0])] * 0.6\n",
    "display(Audio(audio1+audio2, rate=44100))\n",
    "\n",
    "hvo_seq_bass.to_html_plot(show_figure=True, width=1400, height=150, filename='Original Bass')\n",
    "hvo_seq.to_html_plot(show_figure=True, width=1400, height=400)"
   ],
   "id": "1ca1ed676bf1a07a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\n",
   "id": "396e38da29cfe182",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def batch_data_extractor(data_, device='cpu'):\n",
    "\n",
    "    bass_solo = data_[0].to(device) if data_[0].device.type != device else data_[0]\n",
    "    drums = data_[1].to(device) if data_[1].device.type != device else data_[1]\n",
    "    stacked_bass_drums = data_[2].to(device) if data_[2].device.type != device else data_[2]\n",
    "    shifted_drums = data_[3].to(device) if data_[3].device.type != device else data_[3]\n",
    "\n",
    "    return bass_solo, drums, stacked_bass_drums, shifted_drums\n",
    "\n",
    "\n",
    "def predict_using_batch_data(batch_data, model_=model, device='cpu', mute_bass=False, max_n_bars=32):\n",
    "    model_.eval()\n",
    "\n",
    "\n",
    "\n",
    "    bass_solo, drums, stacked_bass_drums, shifted_drums = batch_data_extractor(\n",
    "        data_=batch_data,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        h, v, o, hvo, h_logits = model_.sample(\n",
    "            src=bass_solo[:, :max_n_bars*16, :] if not mute_bass else torch.zeros_like(bass_solo[:, :max_n_bars*16, :]),\n",
    "            tgt=shifted_drums[:, :max_n_bars*16, :],\n",
    "\n",
    "        )\n",
    "    return hvo, h_logits"
   ],
   "id": "577105352d6d48b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample_ix = torch.randint(0, len(test_dataset), (1,)).item()\n",
    "bass_solo, drums, stacked_bass_drums, shifted_drums = batch_data_extractor(\n",
    "    data_=test_dataset[sample_ix],\n",
    "    device='cpu'\n",
    ")\n",
    "shifted_drums[1, :] == drums[0, :]\n"
   ],
   "id": "ce7eb992ba382da5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# select a random sample\n",
    "import numpy as np\n",
    "import timeit\n",
    "sample_ix = np.random.randint(0, len(test_dataset))\n",
    "print(sample_ix)\n",
    "\n",
    "hvo, h_logits = predict_using_batch_data(test_dataset[sample_ix:sample_ix+1], model_=model, max_n_bars=32, mute_bass=False)\n",
    "\n",
    "hvo_gt = test_dataset.instrument2_hvos[sample_ix]\n",
    "hvo_shifted = test_dataset.instrument2_shifted_hvos[sample_ix]\n",
    "\n",
    "\n",
    "total = torch.cat([hvo[0], hvo_gt[:32, :]], dim=0)\n",
    "\n",
    "\n",
    "hvo_seq = HVO_Sequence(\n",
    "    beat_division_factors=[4],\n",
    "    drum_mapping=ROLAND_REDUCED_MAPPING,\n",
    ")\n",
    "hvo_seq.add_tempo(0, 120)\n",
    "hvo_seq.add_time_signature(0, 4, 4) \n",
    "print(total.cpu().numpy().shape) \n",
    "hvo_seq.hvo = total.cpu().numpy()\n",
    "hvo_seq.to_html_plot(show_figure=True, width=1400, height=400)\n",
    "\n",
    "hvo[0, 0, :]\n"
   ],
   "id": "add872422909b0ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hvo_seq2 = HVO_Sequence(\n",
    "    beat_division_factors=[4], \n",
    "    drum_mapping=ROLAND_REDUCED_MAPPING\n",
    ")\n",
    "hvo_seq2.add_tempo(0, 120)\n",
    "hvo_seq2.add_time_signature(0, 4, 4)\n",
    "hvo_seq2.hvo = torch.cat([hvo[0]], dim=0).cpu().numpy()\n",
    "\n",
    "# load audio player\n",
    "from IPython.display import Audio\n",
    "Audio(hvo_seq2.synthesize(sf_path='hvo_sequence/soundfonts/Standard_Drum_Kit.sf2'), rate=44100)\n"
   ],
   "id": "78aaf94701953ae3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# hvo_seq = HVO_Sequence(\n",
    "#     beat_division_factors=[4],\n",
    "#     drum_mapping=ROLAND_REDUCED_MAPPING\n",
    "# )\n",
    "# hvo_seq.add_tempo(0, 120)\n",
    "# hvo_seq.add_time_signature(0, 4, 4) \n",
    "# print(total.cpu().numpy().shape) \n",
    "# hvo_seq.hvo = hvo_shifted.cpu().numpy()\n",
    "# hvo_seq.to_html_plot(show_figure=True, width=1400, height=400)\n",
    "# \n",
    "# hvo_seq = HVO_Sequence(\n",
    "#     beat_division_factors=[4],\n",
    "#     drum_mapping=ROLAND_REDUCED_MAPPING\n",
    "# )\n",
    "# hvo_seq.add_tempo(0, 120)\n",
    "# hvo_seq.add_time_signature(0, 4, 4) \n",
    "# print(total.cpu().numpy().shape) \n",
    "# hvo_seq.hvo = hvo_gt.cpu().numpy()\n",
    "# hvo_seq.to_html_plot(show_figure=True, width=1400, height=400)\n",
    "\n"
   ],
   "id": "de214a7ff2ea2957",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Auto-regressive prediction\n",
    "def predict_using_batch_data_auto_Reg(batch_data, model_=model, device='cpu', max_n_bars=32, mute_bass=False,\n",
    "                                      prime_with_this_hvo=None, mask_bass_vel=True, mask_dec_in_vel=True, use_bernulli=True, temperature=1.0, threshold=0.5, reproduceable=False, \n",
    "                                      remove_kicks=False, remove_snares=False, remove_hats=False, remove_toms=False, remove_crashs=False, remove_rides=False):\n",
    "    model_.eval()\n",
    "    \n",
    "    assert not (reproduceable and use_bernulli), \"Cannot use be reproduceable if use_bernulli\"\n",
    "    \n",
    "    bass_solo_, drums_, stacked_bass_drums_, shifted_drums_ = batch_data_extractor(\n",
    "        data_=batch_data,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    bass_solo = bass_solo_.clone()\n",
    "    shifted_drums = shifted_drums_.clone()\n",
    "    \n",
    "    if mask_dec_in_vel:\n",
    "        shifted_drums[:, :, 9:18] = 0\n",
    "         \n",
    "    if isinstance(mask_bass_vel, bool) and mask_bass_vel:\n",
    "        bass_solo[:, :, 1] = 0\n",
    "    elif isinstance(mask_bass_vel, float):\n",
    "        bass_solo[:, :, 1] *= mask_bass_vel\n",
    "\n",
    "    \n",
    "    if prime_with_this_hvo is None:\n",
    "        shifted_in = torch.zeros((1, (max_n_bars) * 16 + 1, 27))\n",
    "        gens = torch.zeros((1, (max_n_bars) * 16, 27))\n",
    "        start_at = 0\n",
    "    else:\n",
    "        assert prime_with_this_hvo.shape[0] % 16 == 0\n",
    "        shifted_in = torch.zeros((1, max_n_bars * 16 + prime_with_this_hvo.shape[0] + 1, 27))\n",
    "        gens = torch.zeros((1, max_n_bars * 16  + prime_with_this_hvo.shape[0], 27))\n",
    "        start_at = prime_with_this_hvo.shape[0]\n",
    "        shifted_in[:, 1:start_at+1, :] = prime_with_this_hvo.unsqueeze(0)[:, :, :]\n",
    "        gens[:, :start_at, :] = prime_with_this_hvo.unsqueeze(0)[:, :, :]\n",
    "        \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    print(\"Starting prediction at bar: \", start_at)\n",
    "    for i in range(start_at, max_n_bars * 16):\n",
    "        n_quarter_notes = int(i // 4) + 1\n",
    "        with torch.no_grad():\n",
    "            if (i - start_at) < 32 and not reproduceable:\n",
    "                thresh = 0.05\n",
    "                sample_bernulli = use_bernulli\n",
    "            else:\n",
    "                thresh = threshold\n",
    "                sample_bernulli = use_bernulli\n",
    "\n",
    "            h, v, o, hvo_, h_logits = model_.sample(\n",
    "                src=bass_solo[:, :n_quarter_notes * 4, :] if not mute_bass else torch.zeros_like(bass_solo[:, :n_quarter_notes * 4, :]),\n",
    "                tgt=shifted_in[:, :i+1, :],\n",
    "                scale_vel=1.0,\n",
    "                threshold=thresh,\n",
    "                use_bernulli=sample_bernulli,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            \n",
    "            if remove_kicks:\n",
    "                hvo_[:, :, 0::9] = 0\n",
    "            if remove_snares:\n",
    "                hvo_[:, :, 1::9] = 0\n",
    "            if remove_hats:\n",
    "                hvo_[:, :, 2::9] = 0\n",
    "                hvo_[0, :, 3::9] = 0\n",
    "            if remove_toms:\n",
    "                hvo_[:, :, 4::9] = 0\n",
    "                hvo_[:, :, 5::9] = 0\n",
    "                hvo_[:, :, 6::9] = 0\n",
    "            if remove_crashs:\n",
    "                hvo_[:, :, 7::9] = 0\n",
    "            if remove_rides:\n",
    "                hvo_[:, :, 8::9] = 0\n",
    "        \n",
    "        gens[:, i, :] = hvo_[:, i, :].clone()\n",
    "        shifted_in[:, i+1, :] = hvo_[:, i, :]\n",
    "        shifted_in[:, :,  9:18] = 0\n",
    "\n",
    "    print('Time: ', (timeit.default_timer() - start) * 1000, 'ms')\n",
    "        \n",
    "    return gens, h_logits"
   ],
   "id": "53414c6e7cd61ef2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "# sample_ix = np.random.randint(0, len(test_dataset))\n",
    "# select a random 2 bar sample \n",
    "sample_ix = np.random.randint(0, len(test_dataset)) #2373, 3819,1220, 3782, 1539, 1966, 2902, 2507\n",
    "print(sample_ix)\n",
    "random_hvo = test_dataset.instrument2_hvos[np.random.randint(0, len(test_dataset))][-32:, :]\n",
    "primer_hvo = test_dataset.instrument2_hvos[sample_ix][:32, :]\n",
    "\n",
    "use_bernulli = True\n",
    "reproduceable = False\n",
    "temperature = 1\n",
    "threshold = 0.0\n",
    "\n",
    "hvo, h_logits_w_bass = predict_using_batch_data_auto_Reg(\n",
    "    test_dataset[sample_ix:sample_ix+1], model_=model, max_n_bars=32, mute_bass=False, prime_with_this_hvo=None,\n",
    "    mask_bass_vel=True, mask_dec_in_vel=True,\n",
    "    use_bernulli=use_bernulli, temperature=temperature, threshold=threshold, reproduceable=reproduceable, remove_kicks=False, remove_snares=False, remove_hats=False, remove_toms=False, remove_crashs=True, remove_rides=False)\n",
    "\n",
    "# hvo_gt = test_dataset.instrument2_hvos[sample_ix][-64:, :]\n",
    "\n",
    "\n",
    "\n",
    "total = torch.cat([hvo[0, :, :]], dim=0)\n",
    "\n",
    "\n",
    "hvo_seq = HVO_Sequence(\n",
    "    beat_division_factors=[4],\n",
    "    drum_mapping=ROLAND_REDUCED_MAPPING\n",
    ")\n",
    "\n",
    "hvo_seq.add_tempo(0, 120)\n",
    "hvo_seq.add_time_signature(0, 4, 4)\n",
    "print(total.cpu().numpy().shape)\n",
    "hvo_seq.hvo = total.cpu().numpy()\n",
    "\n",
    "bass_map = {'BASS Rhythm': [80]}\n",
    "\n",
    "hvo_seq_bass = HVO_Sequence(\n",
    "    beat_division_factors=[4],\n",
    "    drum_mapping=bass_map\n",
    ")\n",
    "hvo_seq_bass.add_tempo(0, 120)\n",
    "hvo_seq_bass.add_time_signature(0, 4, 4)\n",
    "hvo_seq_bass.hvo = test_dataset.instrument1_hvos[sample_ix].cpu().numpy()\n",
    "\n",
    "# load audio player\n",
    "from IPython.display import Audio, display\n",
    "audio1 = hvo_seq.synthesize(sf_path='hvo_sequence/soundfonts/Standard_Drum_Kit.sf2')\n",
    "audio2 = hvo_seq_bass.synthesize(sf_path='hvo_sequence/soundfonts/Standard_Drum_Kit.sf2',track_n=9, program=0)\n",
    "audio1 = audio1[:min(audio1.shape[0], audio2.shape[0])]\n",
    "audio2 = audio2[:min(audio1.shape[0], audio2.shape[0])] * 0.6\n",
    "display(Audio(audio1+audio2, rate=44100))\n",
    "\n",
    "hvo_seq_bass.to_html_plot(show_figure=True, width=1400, height=150, filename='Original Bass')\n",
    "\n",
    "hvo_seq.to_html_plot(show_figure=True, width=1400, height=400, filename='Drums With Original Bass')\n",
    "\n",
    "hvo[0, 0, :]"
   ],
   "id": "9a64783d7c839ae0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# show logits above one another as a heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "h_probs_w_bass = torch.sigmoid(h_logits_w_bass[0, :, :]).cpu().numpy().transpose()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 2))\n",
    "# use a grey scale colormap with white being the lowest value\n",
    "\n",
    "# h_probs_w_bass[h_probs_w_bass < threshold] = 0\n",
    "\n",
    "sns.heatmap(h_probs_w_bass, ax=ax, cmap='Greys')\n",
    "\n",
    "# flip the y-axis so that the first row of the matrix is at the top\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.show()"
   ],
   "id": "12dfc6b1bc716348",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "h_probs_w_bass",
   "id": "39daed89589c7244",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4af7c20122f4c7cd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
